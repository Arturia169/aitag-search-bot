"""AI generation parameter parser and explainer."""

import re
import json
import logging
from typing import Dict, Optional

logger = logging.getLogger(__name__)


# Parameter explanations in Chinese
PARAM_EXPLANATIONS = {
    "steps": {
        "name": "è¿­ä»£æ­¥æ•° (Steps)",
        "desc": "ç”Ÿæˆè¿‡ç¨‹çš„è¿­ä»£æ¬¡æ•°ã€‚æ­¥æ•°è¶Šé«˜ï¼Œç»†èŠ‚è¶Šä¸°å¯Œï¼Œä½†ç”Ÿæˆæ—¶é—´ä¹Ÿè¶Šé•¿ã€‚é€šå¸¸ 20-30 æ­¥å°±èƒ½è·å¾—ä¸é”™çš„æ•ˆæœã€‚"
    },
    "sampler": {
        "name": "é‡‡æ ·å™¨ (Sampler)",
        "desc": "æ§åˆ¶å›¾åƒç”Ÿæˆç®—æ³•çš„æ ¸å¿ƒç»„ä»¶ã€‚ä¸åŒé‡‡æ ·å™¨ä¼šäº§ç”Ÿä¸åŒé£æ ¼çš„ç”»é¢ã€‚å¸¸è§çš„æœ‰ Eulerã€DPM++ã€DDIM ç­‰ã€‚"
    },
    "cfg scale": {
        "name": "æç¤ºè¯å¼•å¯¼å¼ºåº¦ (CFG Scale)",
        "desc": "å†³å®š AI å¯¹ä½ è¾“å…¥çš„æç¤ºè¯çš„éµå¾ªç¨‹åº¦ã€‚æ•°å€¼è¶Šé«˜è¶Š'å¬è¯'ä½†å¯èƒ½è¿‡åº¦é¥±å’Œï¼›è¶Šä½åˆ™æ›´'åˆ›æ„'ä½†å¯èƒ½åç¦»ä¸»é¢˜ã€‚æ¨è 5-12ã€‚"
    },
    "seed": {
        "name": "éšæœºç§å­ (Seed)",
        "desc": "å†³å®šç”»é¢éšæœºæ€§çš„é­”æ³•æ•°å­—ã€‚ç›¸åŒçš„ç§å­ + ç›¸åŒçš„å‚æ•° = ç›¸åŒçš„ç”»é¢ã€‚ç”¨äºå¤ç°æˆ–å¾®è°ƒä½œå“ã€‚"
    },
    "size": {
        "name": "å°ºå¯¸ (Size)",
        "desc": "è¾“å‡ºå›¾åƒçš„åˆ†è¾¨ç‡ (å®½Ã—é«˜)ã€‚å¸¸è§æ¯”ä¾‹æœ‰ 1:1 (å¤´åƒ)ã€16:9 (å£çº¸)ã€2:3 (äººåƒ) ç­‰ã€‚"
    },
    "model": {
        "name": "æ¨¡å‹ (Model)",
        "desc": "AI ç»˜ç”»çš„'å¤§è„‘'ã€‚ä¸åŒæ¨¡å‹æ“…é•¿ä¸åŒé£æ ¼ï¼Œå¦‚å†™å®ã€åŠ¨æ¼«ã€æ’ç”»ç­‰ã€‚è¿™æ˜¯å½±å“ç”»é¢é£æ ¼çš„æœ€å…³é”®å› ç´ ã€‚"
    },
    "checkpoint": {
        "name": "åŸºç¡€æ¨¡å‹ (Checkpoint)",
        "desc": "ComfyUI ä¸­çš„ä¸»æ¨¡å‹æ–‡ä»¶ã€‚å†³å®šç”»é¢çš„æ•´ä½“é£æ ¼å’Œè´¨é‡ã€‚"
    },
    "model hash": {
        "name": "æ¨¡å‹å“ˆå¸Œ (Model Hash)",
        "desc": "æ¨¡å‹æ–‡ä»¶çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºç²¾ç¡®åŒ¹é…ç‰¹å®šç‰ˆæœ¬çš„æ¨¡å‹ã€‚"
    },
    "clip skip": {
        "name": "CLIP å±‚è·³è¿‡ (Clip Skip)",
        "desc": "è·³è¿‡ CLIP æ–‡æœ¬ç¼–ç å™¨çš„åå‡ å±‚ã€‚æ•°å€¼è¶Šå¤§ï¼Œå¯¹æç¤ºè¯çš„ç†è§£è¶Š'æŠ½è±¡'ï¼Œå¸¸ç”¨äºåŠ¨æ¼«é£æ ¼ã€‚"
    },
    "denoising strength": {
        "name": "é™å™ªå¼ºåº¦ (Denoising)",
        "desc": "å›¾ç”Ÿå›¾ (img2img) ä¸“å±å‚æ•°ã€‚æ•°å€¼è¶Šé«˜æ”¹åŠ¨è¶Šå¤§ï¼Œè¶Šä½åˆ™è¶Šæ¥è¿‘åŸå›¾ã€‚"
    },
    "schedule type": {
        "name": "è°ƒåº¦ç±»å‹ (Schedule)",
        "desc": "æ§åˆ¶é‡‡æ ·è¿‡ç¨‹ä¸­å™ªå£°å»é™¤çš„èŠ‚å¥ã€‚ä¸åŒè°ƒåº¦å™¨ä¼šå½±å“æœ€ç»ˆç”»é¢çš„è´¨æ„Ÿã€‚"
    },
    "vae": {
        "name": "VAE æ¨¡å‹",
        "desc": "å˜åˆ†è‡ªç¼–ç å™¨ï¼Œè´Ÿè´£å›¾åƒçš„ç¼–è§£ç ã€‚ä¸åŒ VAE ä¼šå½±å“é¢œè‰²é¥±å’Œåº¦å’Œç»†èŠ‚è¡¨ç°ã€‚"
    },
    "lora": {
        "name": "LoRA å¾®è°ƒæ¨¡å‹",
        "desc": "è½»é‡çº§å¾®è°ƒæ¨¡å‹ï¼Œç”¨äºæ·»åŠ ç‰¹å®šè§’è‰²ã€é£æ ¼æˆ–æ¦‚å¿µï¼Œæ— éœ€æ›¿æ¢ä¸»æ¨¡å‹ã€‚"
    },
    "workflow": {
        "name": "å·¥ä½œæµç±»å‹",
        "desc": "è¯¥ä½œå“ä½¿ç”¨çš„ç”Ÿæˆå·¥å…·ç±»å‹ï¼Œå¦‚ ComfyUIã€Stable Diffusion WebUI ç­‰ã€‚"
    }
}


def parse_comfyui_workflow(text: str) -> Dict[str, str]:
    """Parse ComfyUI workflow JSON to extract parameters."""
    params = {}
    
    try:
        # Try to find JSON in the text
        # ComfyUI workflows are typically nested JSON objects
        json_match = re.search(r'\{[\s\S]*\}', text)
        if not json_match:
            return params
            
        workflow = json.loads(json_match.group())
        
        # Look for common ComfyUI node types
        loras = []
        
        for node_id, node_data in workflow.items():
            if not isinstance(node_data, dict):
                continue
                
            class_type = node_data.get("class_type", "")
            inputs = node_data.get("inputs", {})
            
            # Checkpoint loaders
            if "Checkpoint" in class_type or "CheckpointLoader" in class_type:
                ckpt_name = inputs.get("ckpt_name", "")
                if ckpt_name:
                    # Clean up the name
                    ckpt_name = ckpt_name.replace(".safetensors", "").replace(".ckpt", "")
                    params["checkpoint"] = ckpt_name
            
            # LoRA loaders
            if "Lora" in class_type or "LoRA" in class_type:
                lora_text = inputs.get("text", "") or inputs.get("lora_name", "")
                if lora_text:
                    # Extract lora name from <lora:name:weight> format
                    lora_match = re.search(r'<lora:([^:>]+)', lora_text)
                    if lora_match:
                        loras.append(lora_match.group(1))
                    elif not lora_text.startswith("<"):
                        loras.append(lora_text.replace(".safetensors", ""))
            
            # KSampler nodes
            if "KSampler" in class_type or "Sampler" in class_type:
                if "steps" in inputs:
                    params["steps"] = str(inputs["steps"])
                if "cfg" in inputs:
                    params["cfg scale"] = str(inputs["cfg"])
                if "sampler_name" in inputs:
                    params["sampler"] = inputs["sampler_name"]
                if "scheduler" in inputs:
                    params["schedule type"] = inputs["scheduler"]
                if "seed" in inputs:
                    params["seed"] = str(inputs["seed"])
            
            # VAE
            if "VAE" in class_type:
                vae_name = inputs.get("vae_name", "")
                if vae_name:
                    params["vae"] = vae_name.replace(".safetensors", "")
        
        if loras:
            params["lora"] = ", ".join(loras)
        
        if params:
            params["workflow"] = "ComfyUI"
            
    except (json.JSONDecodeError, Exception) as e:
        logger.debug(f"Failed to parse ComfyUI workflow: {e}")
    
    return params


def parse_parameters(prompt_text: str) -> Dict[str, str]:
    """Parse generation parameters from prompt text (supports SD and ComfyUI formats)."""
    if not prompt_text:
        return {}
    
    params = {}
    
    # Method 1: Standard SD format - "Key: Value" patterns
    patterns = [
        r'(Steps|Sampler|CFG scale|Seed|Size|Model|Model hash|Clip skip|Denoising strength|Schedule type|VAE)\s*[:ï¼š]\s*([^,\n]+)',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, prompt_text, re.IGNORECASE)
        for key, value in matches:
            params[key.lower().strip()] = value.strip().rstrip(',')
    
    # LoRA detection in standard format
    lora_matches = re.findall(r'<lora:([^:>]+):[^>]+>', prompt_text, re.IGNORECASE)
    if lora_matches:
        params["lora"] = ", ".join(lora_matches)
    
    # Method 2: If no standard params found, try ComfyUI workflow format
    if not params:
        params = parse_comfyui_workflow(prompt_text)
    
    return params


def explain_parameters(params: Dict[str, str]) -> str:
    """Generate a formatted explanation of parameters."""
    if not params:
        return "ğŸ˜• è¯¥ä½œå“æ²¡æœ‰å¯è§£è¯»çš„å‚æ•°ä¿¡æ¯ã€‚\n\nå¯èƒ½åŸå› ï¼š\nâ€¢ éæ ‡å‡†æ ¼å¼å·¥ä½œæµ\nâ€¢ ä½œè€…æœªå…¬å¼€å‚æ•°\nâ€¢ å‚æ•°å·²è¢«ç§»é™¤"
    
    lines = ["ğŸ¨ <b>AI ç”Ÿæˆå‚æ•°è§£è¯»</b>\n"]
    
    # Show workflow type first if present
    if "workflow" in params:
        lines.append(f"ğŸ“¦ <b>å·¥å…·</b>: {params['workflow']}\n")
    
    for key, value in params.items():
        if key == "workflow":
            continue
        key_lower = key.lower()
        if key_lower in PARAM_EXPLANATIONS:
            info = PARAM_EXPLANATIONS[key_lower]
            lines.append(f"<b>ğŸ“Œ {info['name']}</b>")
            lines.append(f"   å€¼ï¼š<code>{value}</code>")
            lines.append(f"   ğŸ’¡ {info['desc']}\n")
        else:
            lines.append(f"<b>ğŸ“Œ {key}</b>: <code>{value}</code>\n")
    
    return "\n".join(lines)


def get_quick_summary(params: Dict[str, str]) -> str:
    """Get a one-line summary of key parameters."""
    parts = []
    
    # Check for model (SD) or checkpoint (ComfyUI)
    model_name = params.get("model") or params.get("checkpoint")
    if model_name:
        model_name = model_name.split(",")[0].strip()
        if len(model_name) > 20:
            model_name = model_name[:17] + "..."
        parts.append(f"ğŸ¤– {model_name}")
    
    if "steps" in params:
        parts.append(f"ğŸ”„ {params['steps']}æ­¥")
    
    if "cfg scale" in params:
        parts.append(f"ğŸ“Š CFG {params['cfg scale']}")
    
    if "sampler" in params:
        sampler = params["sampler"].split()[0]
        parts.append(f"ğŸ¯ {sampler}")
    
    if "workflow" in params:
        parts.append(f"ğŸ“¦ {params['workflow']}")
    
    return " | ".join(parts) if parts else ""
